{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/7z+PDBZqg/D9Vycpc+5q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbhinayaReddyMalapati/calculator/blob/main/Named_Entity_Recognition_(NER)_and_Feature_Engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 911
        },
        "id": "5rvR4qZ-8t-b",
        "outputId": "dbaca5cc-47ff-4fb3-a127-c166c98dc558"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Columns: Index(['id', 'news_url', 'title', 'tweet_ids'], dtype='object')\n",
            "                     id                                           news_url  \\\n",
            "0  gossipcop-2493749932  www.dailymail.co.uk/tvshowbiz/article-5874213/...   \n",
            "1  gossipcop-4580247171  hollywoodlife.com/2018/05/05/paris-jackson-car...   \n",
            "2   gossipcop-941805037  variety.com/2017/biz/news/tax-march-donald-tru...   \n",
            "3  gossipcop-2547891536  www.dailymail.co.uk/femail/article-3499192/Do-...   \n",
            "4  gossipcop-5476631226  variety.com/2018/film/news/list-2018-oscar-nom...   \n",
            "\n",
            "                                               title  \\\n",
            "0  Did Miley Cyrus and Liam Hemsworth secretly ge...   \n",
            "1  Paris Jackson & Cara Delevingne Enjoy Night Ou...   \n",
            "2  Celebrities Join Tax March in Protest of Donal...   \n",
            "3  Cindy Crawford's daughter Kaia Gerber wears a ...   \n",
            "4      Full List of 2018 Oscar Nominations â€“ Variety   \n",
            "\n",
            "                                           tweet_ids  \n",
            "0  284329075902926848\\t284332744559968256\\t284335...  \n",
            "1  992895508267130880\\t992897935418503169\\t992899...  \n",
            "2  853359353532829696\\t853359576543920128\\t853359...  \n",
            "3  988821905196158981\\t988824206556172288\\t988825...  \n",
            "4  955792793632432131\\t955795063925301249\\t955798...  \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'content'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'content'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-cab857df6e30>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Assuming the relevant text column is named 'content', replace with actual column name if different\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cleaned_text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Named Entity Recognition (NER)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'content'"
          ]
        }
      ],
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import spacy\n",
        "from textblob import TextBlob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load Dataset\n",
        "file_path = \"/content/gossipcop_fake.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Inspect the dataset\n",
        "print(\"Dataset Columns:\", data.columns)\n",
        "print(data.head())\n",
        "\n",
        "# Text Preprocessing\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'<.*?>', '', str(text))  # Remove HTML tags\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove special characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra whitespace\n",
        "    return text.lower()  # Normalize text to lowercase\n",
        "\n",
        "# Assuming the relevant text column is named 'content', replace with actual column name if different\n",
        "data['cleaned_text'] = data['content'].apply(preprocess_text)\n",
        "\n",
        "# Named Entity Recognition (NER)\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def extract_entities(text):\n",
        "    doc = nlp(text)\n",
        "    entity_counts = {'ORG': 0, 'PERSON': 0, 'GPE': 0}\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ in entity_counts:\n",
        "            entity_counts[ent.label_] += 1\n",
        "    return entity_counts\n",
        "\n",
        "data['entities'] = data['cleaned_text'].apply(extract_entities)\n",
        "data['org_count'] = data['entities'].apply(lambda x: x['ORG'])\n",
        "data['person_count'] = data['entities'].apply(lambda x: x['PERSON'])\n",
        "data['gpe_count'] = data['entities'].apply(lambda x: x['GPE'])\n",
        "\n",
        "# Feature Engineering\n",
        "data['article_length'] = data['cleaned_text'].apply(lambda x: len(x.split()))\n",
        "data['sentiment'] = data['cleaned_text'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
        "\n",
        "# Assuming there is an engagement metric column, replace 'engagement_metric' with the correct column name\n",
        "# Example: likes, shares, comments, etc.\n",
        "if 'engagement_metric' in data.columns:\n",
        "    y = data['engagement_metric']\n",
        "else:\n",
        "    print(\"No engagement metric found. Add appropriate column or modify this step.\")\n",
        "    y = None\n",
        "\n",
        "# Define features\n",
        "feature_columns = ['org_count', 'person_count', 'gpe_count', 'article_length', 'sentiment']\n",
        "X = data[feature_columns]\n",
        "\n",
        "# Model Training and Evaluation (if engagement metric is available)\n",
        "if y is not None:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    model = RandomForestRegressor(random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    print(\"Mean Absolute Error:\", mean_absolute_error(y_test, y_pred))\n",
        "    print(\"R2 Score:\", r2_score(y_test, y_pred))\n",
        "\n",
        "    # Visualization\n",
        "    # Bar chart for entity frequencies\n",
        "    entity_totals = data[['org_count', 'person_count', 'gpe_count']].sum()\n",
        "    entity_totals.plot(kind='bar', title='Entity Frequency in Articles')\n",
        "    plt.show()\n",
        "\n",
        "    # Scatter plot: Sentiment vs Engagement\n",
        "    plt.scatter(data['sentiment'], y)\n",
        "    plt.title('Sentiment vs Engagement')\n",
        "    plt.xlabel('Sentiment Score')\n",
        "    plt.ylabel('Engagement Metric')\n",
        "    plt.show()\n",
        "\n",
        "    # Heatmap of Feature Correlation\n",
        "    correlation_matrix = data[feature_columns + ['engagement_metric']].corr()\n",
        "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
        "    plt.title('Feature Correlation')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Engagement metric is not available. Model training and evaluation skipped.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Cwyo_j-_UNJ",
        "outputId": "6db3bee9-2c4a-4e52-e9f6-9ab46f672f8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['id', 'news_url', 'title', 'tweet_ids'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import spacy\n",
        "from textblob import TextBlob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load Dataset\n",
        "file_path = \"/content/gossipcop_fake.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Inspect the dataset\n",
        "print(\"Dataset Columns:\", data.columns)\n",
        "print(data.head())\n",
        "\n",
        "# Identify the text column (replace 'text_column' with the actual column name containing text data)\n",
        "# Uncomment the line below after inspecting the columns:\n",
        "# text_column = 'text_column'  # Replace this with the actual column name\n",
        "text_column = data.columns[0]  # Default to the first column if unsure\n",
        "\n",
        "# Text Preprocessing\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'<.*?>', '', str(text))  # Remove HTML tags\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove special characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra whitespace\n",
        "    return text.lower()  # Normalize text to lowercase\n",
        "\n",
        "data['cleaned_text'] = data[text_column].apply(preprocess_text)\n",
        "\n",
        "# Named Entity Recognition (NER)\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def extract_entities(text):\n",
        "    doc = nlp(text)\n",
        "    entity_counts = {'ORG': 0, 'PERSON': 0, 'GPE': 0}\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ in entity_counts:\n",
        "            entity_counts[ent.label_] += 1\n",
        "    return entity_counts\n",
        "\n",
        "data['entities'] = data['cleaned_text'].apply(extract_entities)\n",
        "data['org_count'] = data['entities'].apply(lambda x: x['ORG'])\n",
        "data['person_count'] = data['entities'].apply(lambda x: x['PERSON'])\n",
        "data['gpe_count'] = data['entities'].apply(lambda x: x['GPE'])\n",
        "\n",
        "# Feature Engineering\n",
        "data['article_length'] = data['cleaned_text'].apply(lambda x: len(x.split()))\n",
        "data['sentiment'] = data['cleaned_text'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
        "\n",
        "# Assuming there is an engagement metric column, replace 'engagement_metric' with the correct column name\n",
        "# Example: likes, shares, comments, etc.\n",
        "if 'engagement_metric' in data.columns:\n",
        "    y = data['engagement_metric']\n",
        "else:\n",
        "    print(\"No engagement metric found. Add appropriate column or modify this step.\")\n",
        "    y = None\n",
        "\n",
        "# Define features\n",
        "feature_columns = ['org_count', 'person_count', 'gpe_count', 'article_length', 'sentiment']\n",
        "X = data[feature_columns]\n",
        "\n",
        "# Model Training and Evaluation (if engagement metric is available)\n",
        "if y is not None:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    model = RandomForestRegressor(random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    print(\"Mean Absolute Error:\", mean_absolute_error(y_test, y_pred))\n",
        "    print(\"R2 Score:\", r2_score(y_test, y_pred))\n",
        "\n",
        "    # Visualization\n",
        "    # Bar chart for entity frequencies\n",
        "    entity_totals = data[['org_count', 'person_count', 'gpe_count']].sum()\n",
        "    entity_totals.plot(kind='bar', title='Entity Frequency in Articles')\n",
        "    plt.show()\n",
        "\n",
        "    # Scatter plot: Sentiment vs Engagement\n",
        "    plt.scatter(data['sentiment'], y)\n",
        "    plt.title('Sentiment vs Engagement')\n",
        "    plt.xlabel('Sentiment Score')\n",
        "    plt.ylabel('Engagement Metric')\n",
        "    plt.show()\n",
        "\n",
        "    # Heatmap of Feature Correlation\n",
        "    correlation_matrix = data[feature_columns + ['engagement_metric']].corr()\n",
        "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
        "    plt.title('Feature Correlation')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Engagement metric is not available. Model training and evaluation skipped.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGA7wCPZ_YbF",
        "outputId": "5023ec55-9bce-4bbb-a825-c4598c3ae5d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Columns: Index(['id', 'news_url', 'title', 'tweet_ids'], dtype='object')\n",
            "                     id                                           news_url  \\\n",
            "0  gossipcop-2493749932  www.dailymail.co.uk/tvshowbiz/article-5874213/...   \n",
            "1  gossipcop-4580247171  hollywoodlife.com/2018/05/05/paris-jackson-car...   \n",
            "2   gossipcop-941805037  variety.com/2017/biz/news/tax-march-donald-tru...   \n",
            "3  gossipcop-2547891536  www.dailymail.co.uk/femail/article-3499192/Do-...   \n",
            "4  gossipcop-5476631226  variety.com/2018/film/news/list-2018-oscar-nom...   \n",
            "\n",
            "                                               title  \\\n",
            "0  Did Miley Cyrus and Liam Hemsworth secretly ge...   \n",
            "1  Paris Jackson & Cara Delevingne Enjoy Night Ou...   \n",
            "2  Celebrities Join Tax March in Protest of Donal...   \n",
            "3  Cindy Crawford's daughter Kaia Gerber wears a ...   \n",
            "4      Full List of 2018 Oscar Nominations â€“ Variety   \n",
            "\n",
            "                                           tweet_ids  \n",
            "0  284329075902926848\\t284332744559968256\\t284335...  \n",
            "1  992895508267130880\\t992897935418503169\\t992899...  \n",
            "2  853359353532829696\\t853359576543920128\\t853359...  \n",
            "3  988821905196158981\\t988824206556172288\\t988825...  \n",
            "4  955792793632432131\\t955795063925301249\\t955798...  \n",
            "No engagement metric found. Add appropriate column or modify this step.\n",
            "Engagement metric is not available. Model training and evaluation skipped.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import spacy\n",
        "from textblob import TextBlob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load Dataset\n",
        "file_path = \"/content/gossipcop_fake.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Display dataset info\n",
        "print(\"Dataset Columns:\", data.columns)\n",
        "print(\"First 5 Rows of Dataset:\\n\", data.head())\n",
        "\n",
        "# Identify the text column (replace 'text_column' with the actual column name containing text data)\n",
        "# Uncomment the line below after inspecting the columns:\n",
        "# text_column = 'text_column'  # Replace this with the actual column name\n",
        "text_column = data.columns[0]  # Default to the first column if unsure\n",
        "print(f\"Using '{text_column}' as the text column.\")\n",
        "\n",
        "# Text Preprocessing\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'<.*?>', '', str(text))  # Remove HTML tags\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove special characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra whitespace\n",
        "    return text.lower()  # Normalize text to lowercase\n",
        "\n",
        "data['cleaned_text'] = data[text_column].apply(preprocess_text)\n",
        "print(\"Cleaned Text (First 5 Rows):\\n\", data[['cleaned_text']].head())\n",
        "\n",
        "# Named Entity Recognition (NER)\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def extract_entities(text):\n",
        "    doc = nlp(text)\n",
        "    entity_counts = {'ORG': 0, 'PERSON': 0, 'GPE': 0}\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ in entity_counts:\n",
        "            entity_counts[ent.label_] += 1\n",
        "    return entity_counts\n",
        "\n",
        "data['entities'] = data['cleaned_text'].apply(extract_entities)\n",
        "print(\"Extracted Entities (First 5 Rows):\\n\", data[['entities']].head())\n",
        "\n",
        "data['org_count'] = data['entities'].apply(lambda x: x['ORG'])\n",
        "data['person_count'] = data['entities'].apply(lambda x: x['PERSON'])\n",
        "data['gpe_count'] = data['entities'].apply(lambda x: x['GPE'])\n",
        "print(\"Entity Counts (First 5 Rows):\\n\", data[['org_count', 'person_count', 'gpe_count']].head())\n",
        "\n",
        "# Feature Engineering\n",
        "data['article_length'] = data['cleaned_text'].apply(lambda x: len(x.split()))\n",
        "data['sentiment'] = data['cleaned_text'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
        "print(\"Article Length and Sentiment (First 5 Rows):\\n\", data[['article_length', 'sentiment']].head())\n",
        "\n",
        "# Assuming there is an engagement metric column, replace 'engagement_metric' with the correct column name\n",
        "if 'engagement_metric' in data.columns:\n",
        "    y = data['engagement_metric']\n",
        "    print(\"Engagement Metric Summary:\\n\", y.describe())\n",
        "else:\n",
        "    print(\"No engagement metric found. Add appropriate column or modify this step.\")\n",
        "    y = None\n",
        "\n",
        "# Define features\n",
        "feature_columns = ['org_count', 'person_count', 'gpe_count', 'article_length', 'sentiment']\n",
        "X = data[feature_columns]\n",
        "print(\"Feature Set (First 5 Rows):\\n\", X.head())\n",
        "\n",
        "# Model Training and Evaluation (if engagement metric is available)\n",
        "if y is not None:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    model = RandomForestRegressor(random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    print(\"Mean Absolute Error:\", mean_absolute_error(y_test, y_pred))\n",
        "    print(\"R2 Score:\", r2_score(y_test, y_pred))\n",
        "\n",
        "    # Visualization\n",
        "    # Bar chart for entity frequencies\n",
        "    entity_totals = data[['org_count', 'person_count', 'gpe_count']].sum()\n",
        "    print(\"Entity Totals:\\n\", entity_totals)\n",
        "    entity_totals.plot(kind='bar', title='Entity Frequency in Articles')\n",
        "    plt.show()\n",
        "\n",
        "    # Scatter plot: Sentiment vs Engagement\n",
        "    plt.scatter(data['sentiment'], y)\n",
        "    plt.title('Sentiment vs Engagement')\n",
        "    plt.xlabel('Sentiment Score')\n",
        "    plt.ylabel('Engagement Metric')\n",
        "    plt.show()\n",
        "\n",
        "    # Heatmap of Feature Correlation\n",
        "    correlation_matrix = data[feature_columns + ['engagement_metric']].corr()\n",
        "    print(\"Feature Correlation Matrix:\\n\", correlation_matrix)\n",
        "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
        "    plt.title('Feature Correlation')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Engagement metric is not available. Model training and evaluation skipped.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25r9YPyPAFjZ",
        "outputId": "78521c7b-fb9a-4b28-f769-33b13146446c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Columns: Index(['id', 'news_url', 'title', 'tweet_ids'], dtype='object')\n",
            "First 5 Rows of Dataset:\n",
            "                      id                                           news_url  \\\n",
            "0  gossipcop-2493749932  www.dailymail.co.uk/tvshowbiz/article-5874213/...   \n",
            "1  gossipcop-4580247171  hollywoodlife.com/2018/05/05/paris-jackson-car...   \n",
            "2   gossipcop-941805037  variety.com/2017/biz/news/tax-march-donald-tru...   \n",
            "3  gossipcop-2547891536  www.dailymail.co.uk/femail/article-3499192/Do-...   \n",
            "4  gossipcop-5476631226  variety.com/2018/film/news/list-2018-oscar-nom...   \n",
            "\n",
            "                                               title  \\\n",
            "0  Did Miley Cyrus and Liam Hemsworth secretly ge...   \n",
            "1  Paris Jackson & Cara Delevingne Enjoy Night Ou...   \n",
            "2  Celebrities Join Tax March in Protest of Donal...   \n",
            "3  Cindy Crawford's daughter Kaia Gerber wears a ...   \n",
            "4      Full List of 2018 Oscar Nominations â€“ Variety   \n",
            "\n",
            "                                           tweet_ids  \n",
            "0  284329075902926848\\t284332744559968256\\t284335...  \n",
            "1  992895508267130880\\t992897935418503169\\t992899...  \n",
            "2  853359353532829696\\t853359576543920128\\t853359...  \n",
            "3  988821905196158981\\t988824206556172288\\t988825...  \n",
            "4  955792793632432131\\t955795063925301249\\t955798...  \n",
            "Using 'id' as the text column.\n",
            "Cleaned Text (First 5 Rows):\n",
            "           cleaned_text\n",
            "0  gossipcop2493749932\n",
            "1  gossipcop4580247171\n",
            "2   gossipcop941805037\n",
            "3  gossipcop2547891536\n",
            "4  gossipcop5476631226\n",
            "Extracted Entities (First 5 Rows):\n",
            "                             entities\n",
            "0  {'ORG': 0, 'PERSON': 0, 'GPE': 0}\n",
            "1  {'ORG': 0, 'PERSON': 1, 'GPE': 0}\n",
            "2  {'ORG': 0, 'PERSON': 0, 'GPE': 0}\n",
            "3  {'ORG': 0, 'PERSON': 0, 'GPE': 0}\n",
            "4  {'ORG': 0, 'PERSON': 0, 'GPE': 0}\n",
            "Entity Counts (First 5 Rows):\n",
            "    org_count  person_count  gpe_count\n",
            "0          0             0          0\n",
            "1          0             1          0\n",
            "2          0             0          0\n",
            "3          0             0          0\n",
            "4          0             0          0\n",
            "Article Length and Sentiment (First 5 Rows):\n",
            "    article_length  sentiment\n",
            "0               1        0.0\n",
            "1               1        0.0\n",
            "2               1        0.0\n",
            "3               1        0.0\n",
            "4               1        0.0\n",
            "No engagement metric found. Add appropriate column or modify this step.\n",
            "Feature Set (First 5 Rows):\n",
            "    org_count  person_count  gpe_count  article_length  sentiment\n",
            "0          0             0          0               1        0.0\n",
            "1          0             1          0               1        0.0\n",
            "2          0             0          0               1        0.0\n",
            "3          0             0          0               1        0.0\n",
            "4          0             0          0               1        0.0\n",
            "Engagement metric is not available. Model training and evaluation skipped.\n"
          ]
        }
      ]
    }
  ]
}